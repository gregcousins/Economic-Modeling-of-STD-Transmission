{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "\n",
    "\n",
    "def estBetaParams(mu, var):\n",
    "    alpha=((1 - mu) / var - 1 / mu) * mu**2\n",
    "    beta=alpha * (1 / mu - 1)\n",
    "    return alpha,beta\n",
    "\n",
    "def estGammaParams(mu,var):\n",
    "    shape=(mu**2)/var\n",
    "    scale=var/mu\n",
    "    return shape, scale\n",
    "\n",
    "    #Non-Stochastic Parameters Parameters\n",
    "\n",
    "N = 10**6           #250000               # Total population\n",
    "p_3months = 0.3          # Proportion tested every 3 months\n",
    "p_12months = 1-p_3months         # Proportion tested every 12 months\n",
    "tau = 7                # This is our key parameter; the average return time for tests.\n",
    "\n",
    "# The (weighted) average testing proportion for our population (proportion per day)\n",
    "average_daily_testing_proportion = (p_3months/91 + p_12months/365)\n",
    "tests_per_day=N*average_daily_testing_proportion\n",
    "# I think that the generic person will get tested with this probability each day, and so the waiting\n",
    "# time for a test from any given instant is 1/average_testing_proportion (exponential waiting time)\n",
    "# No.... maybe it should be with rate tests_per_day??\n",
    "\n",
    "# Initial conditions\n",
    "E0 = 0.1 * N             # Initial exposed individuals.\n",
    "X0 = N - E0              # Initial susceptible individuals.\n",
    "S0 = 0                   # Initial symptomatic individuals (we assume the symptoms are NOTICEABLE). Symptomatic Individuals are assumed to isolate.\n",
    "A_u0 = 0               # Initial asymptomatic individuals who are untested.\n",
    "A_t0 = 0                 # Initial asympt. who are tested and awating a positive. These individuals will NOT isolate. \n",
    "A_pos0 = 0                 # Initial asympt. positive test. These people are isolating. \n",
    "                   # Initial people with complications \n",
    "\n",
    "\n",
    "#Define the Model \n",
    "\n",
    "def model(Y, t, beta, epsilon, gamma_t, gamma_u, lambda_, theta, omega_r, average_daily_testing_proportion , tau, N):\n",
    "\n",
    "\n",
    "    X, E, S, A_u, A_t, A_pos= Y\n",
    "\n",
    "\n",
    "    # Here, we assume that the only groups driving the spread of infection are the asymptomatic who have not received a positive test\n",
    "    dXdt = -beta*X*(A_u+A_t)/N + gamma_t*S  + gamma_t*A_pos + gamma_u*A_t + (1-theta)*gamma_u*A_u\n",
    "\n",
    "\n",
    "    dEdt = beta*X*(A_u+A_t)/N - epsilon*E\n",
    "\n",
    "\n",
    "    dSdt = (1-lambda_)*epsilon*E + theta*gamma_u*A_u - gamma_t*S \n",
    "\n",
    "\n",
    "    dA_udt = lambda_*epsilon*E - average_daily_testing_proportion*A_u - gamma_u*A_u #I want some proportion to clear, and some proportion to become infectious\n",
    "\n",
    "    dA_tdt = average_daily_testing_proportion*A_u - omega_r*A_t - gamma_u*A_t\n",
    "\n",
    "\n",
    "    dA_posdt = omega_r*A_t - gamma_t*A_pos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return [dXdt, dEdt, dSdt, dA_udt, dA_tdt, dA_posdt]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-700df8eea733>:100: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  percent_detected_cases=total_detected_cases/total_infections_last_year\n"
     ]
    }
   ],
   "source": [
    "tau=14\n",
    "num_trials=500\n",
    "\n",
    "\n",
    "\n",
    "t_points = np.linspace(0, 50 * 365, 50 * 365) #25 years\n",
    "\n",
    "\n",
    "# ODE solver parameters\n",
    "abserr = 1.0e-8\n",
    "relerr = 1.0e-6\n",
    "\n",
    "\n",
    "solutions=np.zeros((num_trials,len(t_points), 6))\n",
    "sim_params=np.zeros((num_trials, len(t_points),8))\n",
    "\n",
    "for i in range(num_trials):\n",
    "    solutions[i][0]= [X0, E0, S0, A_u0, A_t0, A_pos0]\n",
    "\n",
    "for i in range(num_trials):\n",
    "    for j in range(1, len(t_points)):\n",
    "\n",
    "        #Stochastic params\n",
    "        beta = np.random.beta(estBetaParams(0.9,0.01)[0],estBetaParams(0.9,0.01)[1])*np.random.gamma(estGammaParams(2.85,1)[0],estGammaParams(2.85,1)[1])/30  \n",
    "        epsilon = 1/(np.random.gamma(estGammaParams(5,1)[0],estGammaParams(5,1)[1])+0.000000000000001) \n",
    "        gamma_t = 1/(np.random.gamma(estGammaParams(7,1)[0],estGammaParams(7,1)[1])+0.00000000000001) \n",
    "        theta=np.random.beta(estBetaParams(0.1,0.01)[0],estBetaParams(0.1,0.01)[1])\n",
    "        gamma_u = 1/(np.random.gamma(estGammaParams(14,3)[0],estGammaParams(14,3)[1])+0.00000000000001) \n",
    "        lambda_ = np.random.beta(estBetaParams(0.9,0.01)[0],estBetaParams(0.9,0.01)[1]) \n",
    "        omega_r = 1/(np.random.gamma(estGammaParams(tau,1)[0], estGammaParams(tau,1)[1])+0.00000000000001)\n",
    "        eta = np.random.beta(estBetaParams(0.0225,0.0075**2)[0],estBetaParams(0.0225,0.0075**2)[1])\n",
    "\n",
    "        #record these for average yearly rates later.\n",
    "        sim_params[i][j]=[beta,epsilon,gamma_t,theta,gamma_u,lambda_,omega_r,eta]\n",
    "\n",
    "\n",
    "        tspan = [t_points[j-1], t_points[j]]\n",
    "\n",
    "        ys = odeint(model, solutions[i][j-1], tspan, args=(beta, epsilon, gamma_t, gamma_u, lambda_, theta, omega_r, average_daily_testing_proportion, tau, N), atol=abserr, rtol=relerr)\n",
    "\n",
    "         # Update the solution\n",
    "        solutions[i][j] = ys[-1]\n",
    "        #print(i,j, solutions[i][j], sum(solutions[i][j]))\n",
    "\n",
    "    #Extract_Last_year_data\n",
    "\n",
    "    last_year_data=[solution[-365:] for solution in solutions]\n",
    "    last_year_params=[params[-365:] for params in sim_params]\n",
    "\n",
    "    #rescale by the population size to get a relativized version:\n",
    "\n",
    "    last_year_data = [[value / N for value in day] for day in last_year_data]\n",
    "\n",
    "    # Average Solution: we shoudld compute the totals for each year before averaging in order to get better stats\n",
    "\n",
    "    E_totals=[]\n",
    "    S_totals=[]\n",
    "    A_u_totals=[]\n",
    "    A_t_totals=[]\n",
    "    A_pos_totals=[]\n",
    "    Infection_totals=[]\n",
    "    Detection_totals=[]\n",
    "    Percent_detection_totals=[]\n",
    "\n",
    "    for i in range(num_trials): \n",
    "\n",
    "            # Initialize variables to store the sum of daily inflows\n",
    "        total_yearly_inflow_E = 0\n",
    "        total_yearly_inflow_S = 0\n",
    "        total_yearly_inflow_A_u = 0\n",
    "        total_yearly_inflow_A_t = 0\n",
    "        total_yearly_inflow_A_pos = 0\n",
    "\n",
    "        # Calculate daily inflow rates for the last year\n",
    "        for j in range(365):\n",
    "            X, E, S, A_u, A_t, A_pos = last_year_data[i][j]\n",
    "            beta, epsilon, gamma_t, theta, gamma_u, lambda_, omega_r, eta = last_year_params[i][j]\n",
    "\n",
    "            # Compute daily inflow rates\n",
    "            daily_inflow_E = beta * X * (A_u + A_t) / N\n",
    "            daily_inflow_S = (1 - lambda_) * epsilon * E + theta * gamma_u * A_u\n",
    "            daily_inflow_A_u = lambda_ * epsilon * E\n",
    "            daily_inflow_A_t = average_daily_testing_proportion * A_u\n",
    "            daily_inflow_A_pos = omega_r * A_t\n",
    "\n",
    "            # Sum the inflows\n",
    "            total_yearly_inflow_E += daily_inflow_E\n",
    "            total_yearly_inflow_S += daily_inflow_S\n",
    "            total_yearly_inflow_A_u += daily_inflow_A_u\n",
    "            total_yearly_inflow_A_t += daily_inflow_A_t\n",
    "            total_yearly_inflow_A_pos += daily_inflow_A_pos\n",
    "\n",
    "\n",
    "        # Total infections for the last year\n",
    "        total_infections_last_year = total_yearly_inflow_E \n",
    "        # Total Detected Cases \n",
    "        total_detected_cases = total_yearly_inflow_S + total_yearly_inflow_A_pos\n",
    "\n",
    "        # Percentage of Cases Detected: \n",
    "        percent_detected_cases=total_detected_cases/total_infections_last_year\n",
    "\n",
    "        E_totals.append(total_yearly_inflow_E)\n",
    "        S_totals.append(total_yearly_inflow_S)\n",
    "        A_u_totals.append(total_yearly_inflow_A_u)\n",
    "        A_t_totals.append(total_yearly_inflow_A_t)\n",
    "        A_pos_totals.append(total_yearly_inflow_A_pos)\n",
    "        Infection_totals.append(total_infections_last_year)\n",
    "        Detection_totals.append(total_detected_cases)\n",
    "        Percent_detection_totals.append(percent_detected_cases)\n",
    "\n",
    "\n",
    "\n",
    "#now compute averages accross all simulations:\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "mean_E_total=np.mean(E_totals)\n",
    "stDev_E_total= np.std(E_totals)\n",
    "conf_E_total = stats.norm.interval(0.95, loc=mean_E_total, scale=stDev_E_total)\n",
    "E_total_stats=[mean_E_total, stDev_E_total,conf_E_total]\n",
    "\n",
    "mean_S_total=np.mean(S_totals)\n",
    "stDev_S_total= np.std(S_totals)\n",
    "conf_S_total = stats.norm.interval(0.95, loc=mean_S_total, scale=stDev_S_total)\n",
    "S_total_stats=[mean_S_total, stDev_S_total,conf_S_total]\n",
    "\n",
    "mean_A_u_total=np.mean(A_u_totals)\n",
    "stDev_A_u_total= np.std(A_u_totals)\n",
    "conf_A_u_total = stats.norm.interval(0.95, loc=mean_A_u_total, scale=stDev_A_u_total)\n",
    "A_u_total_stats=[mean_A_u_total, stDev_A_u_total,conf_A_u_total]\n",
    "\n",
    "mean_A_t_total=np.mean(A_t_totals)\n",
    "stDev_A_t_total= np.std(A_t_totals)\n",
    "conf_A_t_total = stats.norm.interval(0.95, loc=mean_A_t_total, scale=stDev_A_t_total)\n",
    "A_t_total_stats=[mean_A_t_total, stDev_A_t_total,conf_A_t_total]\n",
    "\n",
    "mean_A_pos_total=np.mean(A_pos_totals)\n",
    "stDev_A_pos_total= np.std(A_pos_totals)\n",
    "conf_A_pos_total = stats.norm.interval(0.95, loc=mean_A_pos_total, scale=stDev_A_pos_total)\n",
    "A_pos_total_stats=[mean_A_pos_total, stDev_A_pos_total,conf_A_pos_total]\n",
    "\n",
    "mean_Infection_total=np.mean(Infection_totals)\n",
    "stDev_Infection_total= np.std(Infection_totals)\n",
    "conf_Infection_total = stats.norm.interval(0.95, loc=mean_Infection_total, scale=stDev_Infection_total)\n",
    "Infection_total_stats=[mean_Infection_total, stDev_Infection_total,conf_Infection_total]\n",
    "\n",
    "mean_Detection_total=np.mean(Detection_totals)\n",
    "stDev_Detection_total= np.std(Detection_totals)\n",
    "conf_Detection_total = stats.norm.interval(0.95, loc=mean_Detection_total, scale=stDev_Detection_total)\n",
    "Detection_total_stats=[mean_Detection_total, stDev_Detection_total,conf_Detection_total]\n",
    "\n",
    "\n",
    "mean_Percent_detection_total=np.mean(Percent_detection_totals)\n",
    "stDev_Percent_detection_total= np.std(Percent_detection_totals)\n",
    "conf_Percent_detection_total = stats.norm.interval(0.95, loc=mean_Percent_detection_total, scale=stDev_Percent_detection_total)\n",
    "Percent_detection_total_stats=[mean_Percent_detection_total, stDev_Percent_detection_total,conf_Percent_detection_total]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09100907970711597,\n",
       " 0.040546143294073106,\n",
       " (0.011540099138732454, 0.1704780602754995)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Detection_total_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.2715701361048887e-07,\n",
       " 1.9142394536455696e-07,\n",
       " (5.197297491739417e-08, 8.023410523035836e-07)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Infection_total_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040546143294073106"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(Detection_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10496.247369164312"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.04198498947665725*250000 #tau=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876.1791725312793"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.003504716690125117* 250000 #tau = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.155815585042844"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8.623262340171376e-06*250000 #tau=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22752.269926778994"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.09100907970711597*250000 #tau = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-8689b7a9c41a>:102: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  percent_detected_cases=total_detected_cases/total_infections_last_year\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_detection_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-8689b7a9c41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mPercent_detection_total_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmean_Percent_detection_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstDev_Percent_detection_total\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf_Percent_detection_total\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mdetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_detection_total\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m250000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_detection_total' is not defined"
     ]
    }
   ],
   "source": [
    "detections=[]\n",
    "\n",
    "for tau in range(1,10):\n",
    "    \n",
    "    num_trials=500\n",
    "\n",
    "\n",
    "    t_points = np.linspace(0, 50 * 365, 50 * 365) #25 years\n",
    "\n",
    "\n",
    "    # ODE solver parameters\n",
    "    abserr = 1.0e-8\n",
    "    relerr = 1.0e-6\n",
    "\n",
    "\n",
    "    solutions=np.zeros((num_trials,len(t_points), 6))\n",
    "    sim_params=np.zeros((num_trials, len(t_points),8))\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        solutions[i][0]= [X0, E0, S0, A_u0, A_t0, A_pos0]\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        for j in range(1, len(t_points)):\n",
    "\n",
    "            #Stochastic params\n",
    "            beta = np.random.beta(estBetaParams(0.9,0.01)[0],estBetaParams(0.9,0.01)[1])*np.random.gamma(estGammaParams(2.85,1)[0],estGammaParams(2.85,1)[1])/30  \n",
    "            epsilon = 1/(np.random.gamma(estGammaParams(5,1)[0],estGammaParams(5,1)[1])+0.000000000000001) \n",
    "            gamma_t = 1/(np.random.gamma(estGammaParams(7,1)[0],estGammaParams(7,1)[1])+0.00000000000001) \n",
    "            theta=np.random.beta(estBetaParams(0.1,0.01)[0],estBetaParams(0.1,0.01)[1])\n",
    "            gamma_u = 1/(np.random.gamma(estGammaParams(14,3)[0],estGammaParams(14,3)[1])+0.00000000000001) \n",
    "            lambda_ = np.random.beta(estBetaParams(0.9,0.01)[0],estBetaParams(0.9,0.01)[1]) \n",
    "            omega_r = 1/(np.random.gamma(estGammaParams(tau,1)[0], estGammaParams(tau,1)[1])+0.00000000000001)\n",
    "            eta = np.random.beta(estBetaParams(0.0225,0.0075**2)[0],estBetaParams(0.0225,0.0075**2)[1])\n",
    "\n",
    "            #record these for average yearly rates later.\n",
    "            sim_params[i][j]=[beta,epsilon,gamma_t,theta,gamma_u,lambda_,omega_r,eta]\n",
    "\n",
    "\n",
    "            tspan = [t_points[j-1], t_points[j]]\n",
    "\n",
    "            ys = odeint(model, solutions[i][j-1], tspan, args=(beta, epsilon, gamma_t, gamma_u, lambda_, theta, omega_r, average_daily_testing_proportion, tau, N), atol=abserr, rtol=relerr)\n",
    "\n",
    "             # Update the solution\n",
    "            solutions[i][j] = ys[-1]\n",
    "            #print(i,j, solutions[i][j], sum(solutions[i][j]))\n",
    "\n",
    "        #Extract_Last_year_data\n",
    "\n",
    "        last_year_data=[solution[-365:] for solution in solutions]\n",
    "        last_year_params=[params[-365:] for params in sim_params]\n",
    "\n",
    "        #rescale by the population size to get a relativized version:\n",
    "\n",
    "        last_year_data = [[value / N for value in day] for day in last_year_data]\n",
    "\n",
    "        # Average Solution: we shoudld compute the totals for each year before averaging in order to get better stats\n",
    "\n",
    "        E_totals=[]\n",
    "        S_totals=[]\n",
    "        A_u_totals=[]\n",
    "        A_t_totals=[]\n",
    "        A_pos_totals=[]\n",
    "        Infection_totals=[]\n",
    "        Detection_totals=[]\n",
    "        Percent_detection_totals=[]\n",
    "\n",
    "        for i in range(num_trials): \n",
    "\n",
    "                # Initialize variables to store the sum of daily inflows\n",
    "            total_yearly_inflow_E = 0\n",
    "            total_yearly_inflow_S = 0\n",
    "            total_yearly_inflow_A_u = 0\n",
    "            total_yearly_inflow_A_t = 0\n",
    "            total_yearly_inflow_A_pos = 0\n",
    "\n",
    "            # Calculate daily inflow rates for the last year\n",
    "            for j in range(365):\n",
    "                X, E, S, A_u, A_t, A_pos = last_year_data[i][j]\n",
    "                beta, epsilon, gamma_t, theta, gamma_u, lambda_, omega_r, eta = last_year_params[i][j]\n",
    "\n",
    "                # Compute daily inflow rates\n",
    "                daily_inflow_E = beta * X * (A_u + A_t) / N\n",
    "                daily_inflow_S = (1 - lambda_) * epsilon * E + theta * gamma_u * A_u\n",
    "                daily_inflow_A_u = lambda_ * epsilon * E\n",
    "                daily_inflow_A_t = average_daily_testing_proportion * A_u\n",
    "                daily_inflow_A_pos = omega_r * A_t\n",
    "\n",
    "                # Sum the inflows\n",
    "                total_yearly_inflow_E += daily_inflow_E\n",
    "                total_yearly_inflow_S += daily_inflow_S\n",
    "                total_yearly_inflow_A_u += daily_inflow_A_u\n",
    "                total_yearly_inflow_A_t += daily_inflow_A_t\n",
    "                total_yearly_inflow_A_pos += daily_inflow_A_pos\n",
    "\n",
    "\n",
    "            # Total infections for the last year\n",
    "            total_infections_last_year = total_yearly_inflow_E \n",
    "            # Total Detected Cases \n",
    "            total_detected_cases = total_yearly_inflow_S + total_yearly_inflow_A_pos\n",
    "\n",
    "            # Percentage of Cases Detected: \n",
    "            percent_detected_cases=total_detected_cases/total_infections_last_year\n",
    "\n",
    "            E_totals.append(total_yearly_inflow_E)\n",
    "            S_totals.append(total_yearly_inflow_S)\n",
    "            A_u_totals.append(total_yearly_inflow_A_u)\n",
    "            A_t_totals.append(total_yearly_inflow_A_t)\n",
    "            A_pos_totals.append(total_yearly_inflow_A_pos)\n",
    "            Infection_totals.append(total_infections_last_year)\n",
    "            Detection_totals.append(total_detected_cases)\n",
    "            Percent_detection_totals.append(percent_detected_cases)\n",
    "\n",
    "\n",
    "\n",
    "    #now compute averages accross all simulations:\n",
    "    from scipy import stats\n",
    "\n",
    "\n",
    "    mean_E_total=np.mean(E_totals)\n",
    "    stDev_E_total= np.std(E_totals)\n",
    "    conf_E_total = stats.norm.interval(0.95, loc=mean_E_total, scale=stDev_E_total)\n",
    "    E_total_stats=[mean_E_total, stDev_E_total,conf_E_total]\n",
    "\n",
    "    mean_S_total=np.mean(S_totals)\n",
    "    stDev_S_total= np.std(S_totals)\n",
    "    conf_S_total = stats.norm.interval(0.95, loc=mean_S_total, scale=stDev_S_total)\n",
    "    S_total_stats=[mean_S_total, stDev_S_total,conf_S_total]\n",
    "\n",
    "    mean_A_u_total=np.mean(A_u_totals)\n",
    "    stDev_A_u_total= np.std(A_u_totals)\n",
    "    conf_A_u_total = stats.norm.interval(0.95, loc=mean_A_u_total, scale=stDev_A_u_total)\n",
    "    A_u_total_stats=[mean_A_u_total, stDev_A_u_total,conf_A_u_total]\n",
    "\n",
    "    mean_A_t_total=np.mean(A_t_totals)\n",
    "    stDev_A_t_total= np.std(A_t_totals)\n",
    "    conf_A_t_total = stats.norm.interval(0.95, loc=mean_A_t_total, scale=stDev_A_t_total)\n",
    "    A_t_total_stats=[mean_A_t_total, stDev_A_t_total,conf_A_t_total]\n",
    "\n",
    "    mean_A_pos_total=np.mean(A_pos_totals)\n",
    "    stDev_A_pos_total= np.std(A_pos_totals)\n",
    "    conf_A_pos_total = stats.norm.interval(0.95, loc=mean_A_pos_total, scale=stDev_A_pos_total)\n",
    "    A_pos_total_stats=[mean_A_pos_total, stDev_A_pos_total,conf_A_pos_total]\n",
    "\n",
    "    mean_Infection_total=np.mean(Infection_totals)\n",
    "    stDev_Infection_total= np.std(Infection_totals)\n",
    "    conf_Infection_total = stats.norm.interval(0.95, loc=mean_Infection_total, scale=stDev_Infection_total)\n",
    "    Infection_total_stats=[mean_Infection_total, stDev_Infection_total,conf_Infection_total]\n",
    "\n",
    "    mean_Detection_total=np.mean(Detection_totals)\n",
    "    stDev_Detection_total= np.std(Detection_totals)\n",
    "    conf_Detection_total = stats.norm.interval(0.95, loc=mean_Detection_total, scale=stDev_Detection_total)\n",
    "    Detection_total_stats=[mean_Detection_total, stDev_Detection_total,conf_Detection_total]\n",
    "\n",
    "\n",
    "    mean_Percent_detection_total=np.mean(Percent_detection_totals)\n",
    "    stDev_Percent_detection_total= np.std(Percent_detection_totals)\n",
    "    conf_Percent_detection_total = stats.norm.interval(0.95, loc=mean_Percent_detection_total, scale=stDev_Percent_detection_total)\n",
    "    Percent_detection_total_stats=[mean_Percent_detection_total, stDev_Percent_detection_total,conf_Percent_detection_total]\n",
    "    \n",
    "    detections.append(mean_detection_total*250000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
