{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "def run_simulations(tau, num_trials):\n",
    "    \n",
    "    \n",
    "    def estBetaParams(mu, var):\n",
    "        alpha=((1 - mu) / var - 1 / mu) * mu**2\n",
    "        beta=alpha * (1 / mu - 1)\n",
    "        return alpha,beta\n",
    "\n",
    "    def estGammaParams(mu,var):\n",
    "        shape=(mu**2)/var\n",
    "        scale=var/mu\n",
    "        return shape, scale\n",
    "    \n",
    "        #Non-Stochastic Parameters Parameters\n",
    "\n",
    "    N = 10**6           #250000               # Total population\n",
    "    \n",
    "    \n",
    "    \n",
    "    #How does test sensitivity/specificity fit in? Specificity should be irrelevent because we are concerned with \n",
    "    #routine testing. Low sensitivity should add a flow from A_t back into A_u or something like that (i.e. people who\n",
    "    # receive a false negative (apparently quite a high probability for asymptomatic individuals))\n",
    "    \n",
    "    \n",
    "    # I think that the generic person will get tested with this probability each day, and so the waiting\n",
    "    # time for a test from any given instant is 1/average_testing_proportion (exponential waiting time)\n",
    "    # No.... maybe it should be with rate tests_per_day??\n",
    "    \n",
    "    #Future goals: Stratify according to sexual activity levels. The current rate of partner exchange seems \n",
    "    #.             insufficient to completely capture the dynamics. \n",
    "    \n",
    "    \n",
    "\n",
    "    # Initial conditions\n",
    "    E0 = 0.10 * N             # Initial exposed individuals.\n",
    "    X0 = N - E0              # Initial susceptible individuals.\n",
    "    S0 = 0 # Initial symptomatic individuals (we assume the symptoms are NOTICEABLE). Symptomatic Individuals are assumed to isolate.\n",
    "    A_sc_u0 = 0               # Initial asymptomatic individuals who are untested.\n",
    "    A_sc_t0 = 0                 # Initial asympt. who are tested and awating a positive. These individuals will NOT isolate. \n",
    "    A_sc_pos0 = 0\n",
    "    A_u0 = 0               # Initial asymptomatic individuals who are untested.\n",
    "    A_t0 = 0                 # Initial asympt. who are tested and awating a positive. These individuals will NOT isolate. \n",
    "    A_pos0 = 0              # Initial asympt. positive test. These people are isolating. \n",
    "        \n",
    "        \n",
    "    #Define the Model \n",
    "\n",
    "    def model(Y, t, beta, ppd, sensitivity, epsilon, gamma_t, gamma_u,gamma_sc, lambda_, theta, omega_r, rho, tau, N):\n",
    "\n",
    "\n",
    "        X, E, S, A_u, A_t, A_pos,A_sc_u, A_sc_t, A_sc_pos= Y\n",
    "\n",
    "\n",
    "        # Here, we assume that the only groups driving the spread of infection are the asymptomatic who have not received a positive test\n",
    "        dXdt = -beta*ppd*X*(A_u+A_t+A_sc_u+A_sc_t)/N + gamma_t*(S+A_pos+A_sc_pos)  + gamma_u*(A_u+A_t)\n",
    "\n",
    "        dEdt = beta*ppd*X*(A_u+A_t+A_sc_u+A_sc_t)/N - epsilon*E\n",
    "\n",
    "\n",
    "        dSdt = (1-lambda_)*epsilon*E + gamma_sc*(A_sc_u+A_sc_t) - gamma_t*S\n",
    "\n",
    "\n",
    "        dA_udt = (1-theta)*lambda_*epsilon*E+(1-sensitivity)*omega_r*A_t - rho*A_u - gamma_u*A_u \n",
    "        \n",
    "        \n",
    "        dA_tdt = rho*A_u - omega_r*A_t - gamma_u*A_t \n",
    "\n",
    "\n",
    "        dA_posdt = sensitivity*omega_r*A_t - gamma_t*A_pos\n",
    "        \n",
    "        \n",
    "        dA_sc_udt = theta*lambda_*epsilon*E + (1-sensitivity)*omega_r*A_sc_t - rho*A_sc_u - gamma_sc*A_sc_u\n",
    "        \n",
    "        \n",
    "        dA_sc_tdt = rho*A_sc_u - omega_r*A_sc_t - gamma_sc*A_sc_t \n",
    "        \n",
    "        \n",
    "        dA_sc_posdt = sensitivity*omega_r*A_sc_t - gamma_t*A_sc_pos\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return [dXdt, dEdt, dSdt, dA_udt, dA_tdt, dA_posdt, dA_sc_udt, dA_sc_tdt, dA_sc_posdt]\n",
    "\n",
    "    t_points = np.linspace(0, 30 * 365, 30 * 365) #30 years\n",
    "\n",
    "\n",
    "    # ODE solver parameters\n",
    "    abserr = 1.0e-8\n",
    "    relerr = 1.0e-6\n",
    "\n",
    "\n",
    "    solutions=np.zeros((num_trials,len(t_points), 9))\n",
    "    sim_params=np.zeros((num_trials, len(t_points),11))\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        solutions[i][0]= [X0, E0, S0, A_u0, A_t0, A_pos0, A_sc_u0, A_sc_t0, A_sc_pos0]\n",
    "        \n",
    "    # Run Simulations\n",
    "    \n",
    "    # Calculate distribution parameters once before the loop\n",
    "    beta_params = estBetaParams(0.7, 0.1**2)\n",
    "    ppd_params = estGammaParams(1.143,10**2)\n",
    "    epsilon_params = estGammaParams(5,1)\n",
    "    gamma_t_params = estGammaParams(7,1)\n",
    "    gamma_u_params = estGammaParams(180,25**2)\n",
    "    gamma_sc_params = estGammaParams(14,1)\n",
    "    theta_params = estBetaParams(0.25,0.1**2)\n",
    "    lambda_params = estBetaParams(0.5,0.25**2)\n",
    "    omega_params = estGammaParams(tau,1)\n",
    "    sensitivity_params = estBetaParams(0.6,0.2**2)\n",
    "    \n",
    "    \n",
    "    p_3months = 0.3          # Proportion tested every 3 months\n",
    "    p_12months = 1-p_3months         # Proportion tested every 12 months\n",
    "\n",
    "\n",
    "    # The (weighted) average testing time between tests per person\n",
    "    average_test_waiting_time = 1/(p_3months/91 + p_12months/365)\n",
    "            \n",
    "    rho_params = estGammaParams(average_test_waiting_time, 7**2)\n",
    "\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        for j in range(1, len(t_points)):\n",
    "\n",
    "\n",
    "\n",
    "            #Stochastic params\n",
    "            \n",
    "            # Infection rate is 50% probability of infection per act(drawn from a beta dist) \n",
    "            #this is iota in the paper\n",
    "            beta = np.random.beta(*beta_params)\n",
    "            \n",
    "            #number of partners per day drawn from a gamma dist with mean =4 (per month) resclaled to 30 days. \n",
    "            # This seems a bit high but not unusual for particularly active groups of GBMSM people\n",
    "            # Note, a higher variance may be appropriate here. \n",
    "            # this is xi in the paper\n",
    "            ppd = np.random.gamma(*ppd_params)/30   \n",
    "            \n",
    "            # Inverse of the latency period post infection. Latency estimated to be gamma with mean 5 days\n",
    "            epsilon = 1/(np.random.gamma(*epsilon_params)+ 1e-10)  \n",
    "            \n",
    "            # Clearance rate with treatment. Infection is usually assumed to be resolved in an average of \n",
    "            # 7 days with standard treatment\n",
    "            gamma_t = 1/(np.random.gamma(*gamma_t_params) + 1e-10) \n",
    "            \n",
    "            # Clearance rate for untreated individuals. We assume that most (asymptomatic) individuals will self-clear\n",
    "            # in around two weeks, or else become symptomatic. Note the higher variance. \n",
    "            gamma_u = 1/(np.random.gamma(*gamma_u_params) + 1e-10)\n",
    "            \n",
    "            #rate at which some proportion of individuals become symptomatic\n",
    "            gamma_sc = 1/(np.random.gamma(*gamma_sc_params) + 1e-10)\n",
    "            \n",
    "            theta = np.random.beta(*theta_params)\n",
    "             \n",
    "            lambda_ = np.random.beta(*lambda_params) \n",
    "            \n",
    "            omega_r = 1/(np.random.gamma(*omega_params) + 1e-10)\n",
    "            \n",
    "            sensitivity = np.random.beta(*sensitivity_params)\n",
    "            \n",
    "            # inverse of the average wait is the per capita testing rate \n",
    "            rho = 1/(np.random.gamma(*rho_params) + 1e-10)\n",
    "            #rho = 1/(np.random.exponential((average_test_waiting_time)) + 1e-10)\n",
    "\n",
    "            #record these for average yearly rates later.\n",
    "            sim_params[i][j]=[beta,ppd,sensitivity, epsilon,gamma_t,theta,gamma_u,gamma_sc,lambda_,omega_r, rho]\n",
    "\n",
    "\n",
    "            tspan = [t_points[j-1], t_points[j]]\n",
    "\n",
    "            ys = odeint(model, solutions[i][j-1], tspan, args=(beta, ppd, sensitivity, epsilon, gamma_t, gamma_u,gamma_sc, lambda_, theta, omega_r, rho, tau, N), atol=abserr, rtol=relerr)\n",
    "\n",
    "             # Update the solution\n",
    "            solutions[i][j] = ys[-1]\n",
    "            #print(i,j, solutions[i][j], sum(solutions[i][j]))\n",
    "\n",
    "\n",
    "           # Initialize lists to store totals for each simulation\n",
    "    total_infections_per_simulation = []\n",
    "    total_detected_cases_per_simulation = []\n",
    "    percent_detected_cases_per_simulation = []\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        # Extract the last year's data for this simulation\n",
    "        last_year_data = solutions[i][-365:]\n",
    "        last_year_params = sim_params[i][-365:]\n",
    "\n",
    "        # Initialize variables to store the sum of daily inflows\n",
    "        sum_daily_inflow_E = 0\n",
    "        sum_daily_inflow_S = 0\n",
    "        sum_daily_inflow_A_pos = 0\n",
    "\n",
    "        # Calculate daily inflow rates for the last year of this simulation\n",
    "        for day_data, day_params in zip(last_year_data, last_year_params):\n",
    "            X, E, S, A_u, A_t, A_pos,A_sc_u, A_sc_t, A_sc_pos = day_data\n",
    "            beta,ppd, sensitivity, epsilon, gamma_t, theta, gamma_u, gamma_sc, lambda_, omega_r,rho = day_params\n",
    "\n",
    "            # Compute daily inflow rates\n",
    "            # Note: these are the only relevant flows because we are only considering a case to be \n",
    "            #       detected if it is symptomatic or receives a positive asymptomatic test\n",
    "            daily_inflow_E = beta* ppd * X * (A_u + A_t+A_sc_u+A_sc_t ) / N\n",
    "            daily_inflow_S = (1-lambda_)*epsilon*E + gamma_sc*(A_sc_u+A_sc_t) \n",
    "            daily_inflow_A_pos = sensitivity*omega_r*(A_t+A_sc_t)\n",
    "\n",
    "            # Sum the inflows\n",
    "            sum_daily_inflow_E += daily_inflow_E\n",
    "            sum_daily_inflow_S += daily_inflow_S\n",
    "            sum_daily_inflow_A_pos += daily_inflow_A_pos\n",
    "\n",
    "        # Calculate total yearly inflow for each compartment\n",
    "        total_yearly_inflow_E = sum_daily_inflow_E\n",
    "        total_yearly_inflow_S = sum_daily_inflow_S\n",
    "        total_yearly_inflow_A_pos = sum_daily_inflow_A_pos\n",
    "\n",
    "        # Total infections for the last year\n",
    "        total_infections_last_year = total_yearly_inflow_E\n",
    "\n",
    "        # Total Detected Cases \n",
    "        total_detected_cases = total_yearly_inflow_S + total_yearly_inflow_A_pos\n",
    "        \n",
    "        # Percent Detected Cases\n",
    "        percent_detected_cases = total_detected_cases/total_infections_last_year\n",
    "\n",
    "        # Store the totals for each simulation\n",
    "        total_infections_per_simulation.append(total_infections_last_year)\n",
    "        total_detected_cases_per_simulation.append(total_detected_cases)\n",
    "        percent_detected_cases_per_simulation.append(percent_detected_cases)\n",
    "\n",
    "    # Calculate the stats across all simulations\n",
    "    \n",
    "    #now compute averages accross all simulations:\n",
    "    from scipy import stats\n",
    "    average_total_infections = np.mean(total_infections_per_simulation)\n",
    "    stdev_total_infections=np.std(total_infections_per_simulation)\n",
    "    conf_total_infections=stats.norm.interval(0.95,loc=average_total_infections,scale=stdev_total_infections/np.sqrt(num_trials))\n",
    "    upper_conf_bound_total_infections= average_total_infections+stats.norm.ppf(1-.05)*stdev_total_infections/np.sqrt(num_trials)\n",
    "    total_infection_stats=[average_total_infections,stdev_total_infections, conf_total_infections, upper_conf_bound_total_infections]\n",
    "    \n",
    "    average_total_detected_cases = np.mean(total_detected_cases_per_simulation)\n",
    "    stdev_total_detected_cases=np.std(total_detected_cases_per_simulation)\n",
    "    conf_total_detected_cases=stats.norm.interval(0.95,loc=average_total_detected_cases,scale=stdev_total_detected_cases/np.sqrt(num_trials))\n",
    "    upper_conf_bound_total_detected_cases = average_total_detected_cases+ stats.norm.ppf(1-.05)*stdev_total_detected_cases/np.sqrt(num_trials)\n",
    "    total_detected_cases_stats=[average_total_detected_cases,stdev_total_detected_cases, conf_total_detected_cases,upper_conf_bound_total_detected_cases]\n",
    "    \n",
    "    average_percent_detected_cases = np.mean(percent_detected_cases_per_simulation)\n",
    "    stdev_percent_detected_cases = np.std(percent_detected_cases_per_simulation)\n",
    "    conf_percent_detected_cases = stats.norm.interval(0.95,loc=average_percent_detected_cases, scale=stdev_percent_detected_cases/np.sqrt(num_trials))\n",
    "    upper_conf_bound_percent_detected_cases = average_percent_detected_cases + stats.norm.ppf(1-.05)*stdev_percent_detected_cases/np.sqrt(num_trials)\n",
    "    percent_detected_cases_stats = [average_percent_detected_cases, stdev_percent_detected_cases, conf_percent_detected_cases, upper_conf_bound_percent_detected_cases]\n",
    "   \n",
    "    #Average Solution Scaled\n",
    "    \n",
    "    average_solution=np.mean(solutions, axis=0)/N\n",
    "\n",
    "\n",
    "\n",
    "    return average_solution, total_infection_stats, total_detected_cases_stats, percent_detected_cases_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Define the range of tau values\n",
    "tau_values = np.arange(1,14.5,1)\n",
    "num_trials = 200  # Define the number of trials for each tau value\n",
    "\n",
    "\n",
    "# Initialize lists to store results\n",
    "results_mean = []\n",
    "results_conf_intervals = []\n",
    "average_solutions = []  # List to store average_solution for each tau\n",
    "\n",
    "# DataFrame to store all results for CSV\n",
    "all_results_df = pd.DataFrame()\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "formatted_now = now.strftime(\"%Y%m%d_%H%M%S\")  # Format the datetime\n",
    "excel_filename = f'simulation_results_detailed_{num_trials}_{formatted_now}.xlsx'\n",
    "\n",
    "\n",
    "for tau in tau_values: \n",
    "    print(tau)\n",
    "    \n",
    "    # Run simulations for each tau\n",
    "    average_solution, total_infection_stats, total_detected_cases_stats, percent_detected_cases_stats = run_simulations(tau, num_trials)\n",
    "    average_solutions.append(average_solution[-365:])\n",
    "    \n",
    "    # Store the results\n",
    "    results_mean.append((total_infection_stats[0], total_detected_cases_stats[0],percent_detected_cases_stats[0]))\n",
    "    results_conf_intervals.append((total_infection_stats[2], total_detected_cases_stats[2],percent_detected_cases_stats[2]))\n",
    "    print([(250000/1000000)*i for i in results_mean[-1]])\n",
    "    \n",
    "    # Prepare data for CSV\n",
    "    temp_df = pd.DataFrame({\n",
    "        'Tau': tau,\n",
    "        'Average Total Infections': total_infection_stats[0],\n",
    "        'Infections Std Dev': total_infection_stats[1],\n",
    "        'Infections Conf Interval Lower': total_infection_stats[2][0],\n",
    "        'Infections Conf Interval Upper': total_infection_stats[2][1],\n",
    "        'Upper Confidence Bound, Total Infections': total_infection_stats[3],\n",
    "        'Average Total Detected Cases': total_detected_cases_stats[0],\n",
    "        'Detected Cases Std Dev': total_detected_cases_stats[1],\n",
    "        'Detected Cases Conf Interval Lower': total_detected_cases_stats[2][0],\n",
    "        'Detected Cases Conf Interval Upper': total_detected_cases_stats[2][1],\n",
    "        'Upper Confidence Bound, Total Detected Cases': total_detected_cases_stats[3],\n",
    "        'Average Percent Detected Cases': percent_detected_cases_stats[0],\n",
    "        'Percent Detected Cases Std Dev': percent_detected_cases_stats[1],\n",
    "        'Percent Detected Conf Interval Lower': percent_detected_cases_stats[2][0],\n",
    "        'Percent Detected Conf Interval Upper': percent_detected_cases_stats[2][1],\n",
    "        'Upper Confidence Bound, Percent Detected Cases': percent_detected_cases_stats[3]\n",
    "        \n",
    "    }, index=[0])\n",
    "    all_results_df = pd.concat([all_results_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "N=10**6\n",
    "pop_scaler = 100000 / N\n",
    "\n",
    "\n",
    "# Before rescaling, separate the 'Tau' column\n",
    "tau_column = all_results_df[['Tau']]\n",
    "\n",
    "# Select columns other than 'Tau' to apply the scaler\n",
    "other_columns = all_results_df.drop('Tau', axis=1)\n",
    "\n",
    "# Apply the scaler to these columns\n",
    "scaled_columns = other_columns * pop_scaler\n",
    "\n",
    "# Concatenate the 'Tau' column back with the scaled columns\n",
    "scaled_all_results_df = pd.concat([tau_column, scaled_columns], axis=1)\n",
    "\n",
    "\n",
    "file_path = f'/Users/gregorycousins/Gonnorhea_proj/results/data/simulation_results/simulation_results_confidence_intervals_num_trials_{num_trials}_{formatted_now}.csv'\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "scaled_all_results_df.to_csv(file_path, index=False)\n",
    "\n",
    "# Calculate and print the runtime\n",
    "runtime = end_time - start_time\n",
    "print(f\"The runtime of the code is {runtime} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_all_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results for plotting\n",
    "import datetime\n",
    "\n",
    "# Ensure that LaTeX is enabled in Matplotlib\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "\n",
    "# Get current datetime\n",
    "now = datetime.datetime.now()\n",
    "formatted_now = now.strftime(\"%Y%m%d_%H%M%S\")  # Format the datetime\n",
    "\n",
    "# Unpack the results_mean into separate lists\n",
    "infections_mean, detected_mean, percent_detected_mean = zip(*results_mean)\n",
    "\n",
    "# Scale the mean values (total infections and detected cases) by the pop_scaler\n",
    "infections_mean = [mean * pop_scaler for mean in infections_mean]\n",
    "detected_mean = [mean * pop_scaler for mean in detected_mean]\n",
    "\n",
    "# Scale the confidence intervals\n",
    "infections_conf, detected_conf, percent_detected_conf = zip(*[[(conf[0] * pop_scaler, conf[1] * pop_scaler) for conf in interval] for interval in results_conf_intervals])\n",
    "\n",
    "# Recalculate the errors for scaled data\n",
    "infections_error = [(mean - conf[0], conf[1] - mean) for mean, conf in zip(infections_mean, infections_conf)]\n",
    "detected_error = [(mean - conf[0], conf[1] - mean) for mean, conf in zip(detected_mean, detected_conf)]\n",
    "\n",
    "# Calculate the errors for percent detected cases (no scaling needed)\n",
    "percent_detected_error = [(mean - conf[0], conf[1] - mean) for mean, conf in zip(percent_detected_mean, percent_detected_conf)]\n",
    "\n",
    "\n",
    "# Find the index for tau = 7 in the numpy array\n",
    "tau_7_index = np.where(tau_values == 7)[0][0]  # This will give the index of the first occurrence of tau = 7\n",
    "\n",
    "\n",
    "# Get the mean and error values for tau = 7\n",
    "infections_mean_7 = infections_mean[tau_7_index]\n",
    "detected_mean_7 = detected_mean[tau_7_index]\n",
    "infections_error_7 = infections_error[tau_7_index]\n",
    "detected_error_7 = detected_error[tau_7_index]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(tau_values, infections_mean, '-o', label='Total Infections', markersize=5)\n",
    "plt.fill_between(tau_values, [mean - err[0] for mean, err in zip(infections_mean, infections_error)], \n",
    "                 [mean + err[1] for mean, err in zip(infections_mean, infections_error)], alpha=0.3)\n",
    "\n",
    "plt.plot(tau_values, detected_mean, '-o', label='Total Detected Cases', markersize=5)\n",
    "plt.fill_between(tau_values, [mean - err[0] for mean, err in zip(detected_mean, detected_error)], \n",
    "                 [mean + err[1] for mean, err in zip(detected_mean, detected_error)], alpha=0.3)\n",
    "\n",
    "\n",
    "# Annotations for tau = 7\n",
    "plt.annotate(f'Tau=7: {infections_mean_7:.2f}\\n+/- {infections_error_7[1]:.2f}',\n",
    "             xy=(7, infections_mean_7), xytext=(5, infections_mean_7 * 1.1),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "\n",
    "plt.annotate(f'Tau=7: {detected_mean_7:.2f}\\n+/- {detected_error_7[1]:.2f}',\n",
    "             xy=(7, detected_mean_7), xytext=(9, detected_mean_7 * 0.25),\n",
    "             arrowprops=dict(facecolor='blue', arrowstyle='->'))\n",
    "\n",
    "plt.xlabel(r'Average Result Return Time ($\\tau$ Days)')\n",
    "plt.ylabel(r'Number of Cases per 100,000')\n",
    "plt.title(r\"Total Infections and Detected Cases for Different $\\tau$ Values; N={} Trials\".format(num_trials))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis ticks to show each integer value of Tau\n",
    "plt.xticks(tau_values)\n",
    "\n",
    "\n",
    "\n",
    "# Create a dynamic file name\n",
    "filepath = f'/Users/gregorycousins/Gonnorhea_proj/results/plots/num_trials_{num_trials}_{formatted_now}.png'\n",
    "\n",
    "# Save the plot with the dynamic file name\n",
    "plt.savefig(filepath)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate the errors for percent detected cases\n",
    "percent_detected_error = [(mean - conf[0], conf[1] - mean) for mean, conf in zip(percent_detected_mean, percent_detected_conf)]\n",
    "percent_detected_error = [(100*err[0],100*err[1]) for err in percent_detected_error]\n",
    "\n",
    "# Plotting the percent detected cases\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(tau_values, [100 * prop for prop in percent_detected_mean], '-o', label='Percent Detected Cases', markersize=5)\n",
    "plt.fill_between(tau_values, [100 * (mean - err[0]) for mean, err in zip(percent_detected_mean, percent_detected_error)], \n",
    "                 [100 * (mean + err[1]) for mean, err in zip(percent_detected_mean, percent_detected_error)], alpha=0.3)\n",
    "\n",
    "plt.xlabel(r'Average Result Return Time ($\\tau$ Days)')\n",
    "plt.ylabel(r'Percent Detected Cases')\n",
    "plt.title(r\"Percent Detected Cases for Different $\\tau$ Values; N={} Trials\".format(num_trials))\n",
    "\n",
    "plt.ylim(100*np.min(percent_detected_mean)-5, 100*np.max(percent_detected_mean)+5)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis ticks to show each integer value of Tau\n",
    "plt.xticks(tau_values)\n",
    "\n",
    "\n",
    "# Create a dynamic file name for the percent detected cases plot\n",
    "file_path_percent = f'/Users/gregorycousins/Gonnorhea_proj/results/plots/percent_detected_{num_trials}_{formatted_now}.png'\n",
    "\n",
    "# Save the plot with the dynamic file name\n",
    "plt.savefig(file_path_percent)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
